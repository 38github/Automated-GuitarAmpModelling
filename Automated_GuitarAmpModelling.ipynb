{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect GPU configuration\n",
    "# to inspect full configuration run nvidia-smi on the host\n",
    "# running this container\n",
    "if not torch.cuda.is_available():\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(\"Detected %s gpus\" % torch.cuda.device_count())\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# Inspect software configuration\n",
    "pytorchv = !pip3 show torch | grep Version\n",
    "print(\"Pytorch version: %s\" % pytorchv)\n",
    "tensorflowv = !pip3 show tensorflow | grep Version\n",
    "print(\"Tensorflow version: %s\" % tensorflowv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git repo clone\n",
    "#!git clone https://github.com/MaxPayne86/Automated-GuitarAmpModelling.git\n",
    "#!cd Automated-GuitarAmpModelling && git checkout feature/add-custom-bounds && git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "class StopExecution(Exception):\n",
    "  def _render_traceback_(self):\n",
    "    pass\n",
    "\n",
    "def parse_stats(stats):\n",
    "  with open(stats) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    test_lossESR_final = data['test_lossESR_final']\n",
    "    test_lossESR_best = data['test_lossESR_best']\n",
    "    esr = min(test_lossESR_final, test_lossESR_best)\n",
    "    valuedict = {}\n",
    "    valuedict[\"model_name\"] = model_name\n",
    "    valuedict[\"unit_type\"] = unit_type\n",
    "    valuedict[\"hidden_size\"] = hidden_size\n",
    "    valuedict[\"skip\"] = skip\n",
    "    return [esr, valuedict]\n",
    "\n",
    "def write_results_dict(resultsdict, outfile):\n",
    "  orderedlist = sorted(resultsdict)\n",
    "  counter = 1\n",
    "  for item in orderedlist:\n",
    "    print(\"%d) %s: %s %d | skip = %d | ESR = %.6f\" % (counter, maindict[item]['model_name'], maindict[item]['unit_type'], maindict[item]['hidden_size'], maindict[item]['skip'], item))\n",
    "    counter = counter + 1\n",
    "  with open(outfile, 'w') as fp:\n",
    "    counter = 1\n",
    "    for item in orderedlist:\n",
    "      line = \"%d) %s: %s %d | skip = %d | ESR = %.6f\" % (counter, maindict[item]['model_name'], maindict[item]['unit_type'], maindict[item]['hidden_size'], maindict[item]['skip'], item)\n",
    "      fp.write(\"%s\\n\" % line)\n",
    "      counter = counter + 1\n",
    "\n",
    "# Do not use tensorflow for training in this container (installation is broken)\n",
    "# it is just there for the modelToKeras.py script to generate an RTNeural compatible model file\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Logs all tensorflow messages except INFO, WARNING, and ERROR\n",
    "\n",
    "# Pre-defined network types list\n",
    "types_list_full = [\"GRU-8\", \"GRU-12\", \"LSTM-8\", \"LSTM-12\", \"LSTM-16\", \"LSTM-20\"]\n",
    "types_list_heavy = [\"LSTM-16\", \"LSTM-20\", \"LSTM-40\"]\n",
    "types_list_light = [\"GRU-12\", \"LSTM-12\", \"LSTM-16\"]\n",
    "# A model is defined by name and input/output track(s) plus network type and config\n",
    "model_list = [\n",
    "  {\n",
    "    \"name\": \"US Double Nrm\",\n",
    "    \"input\": \"Recordings/Export/in-gtr-x-org.wav\",\n",
    "    \"target\": \"Recordings/Export/US Double Nrm.wav\",\n",
    "    \"csv\": \"yes\",\n",
    "    \"types_list\": [\"LSTM-12\"],\n",
    "    \"skip\": [1]\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Cali Texas Ch 1\",\n",
    "    \"input\": \"Recordings/Export/in-gtr-x-org.wav\",\n",
    "    \"target\": \"Recordings/Export/Cali Texas Ch 1.wav\",\n",
    "    \"csv\": \"yes\",\n",
    "    \"types_list\": [\"LSTM-12\"],\n",
    "    \"skip\": [1]\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"US Deluxe Nrm\",\n",
    "    \"input\": \"Recordings/Export/in-gtr-x-org.wav\",\n",
    "    \"target\": \"Recordings/Export/US Deluxe Nrm.wav\",\n",
    "    \"csv\": \"yes\",\n",
    "    \"types_list\": types_list_light,\n",
    "    \"skip\": [0, 1]\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"US Small Tweed\",\n",
    "    \"input\": \"Recordings/Export/in-gtr-x-org.wav\",\n",
    "    \"target\": \"Recordings/Export/US Small Tweed.wav\",\n",
    "    \"csv\": \"yes\",\n",
    "    \"types_list\": types_list_light,\n",
    "    \"skip\": [0, 1]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Print model_list \n",
    "#for model in model_list:\n",
    "#  print(\"%s\\n %s\\n %s\\n %s\" % (model['name'], model['input'], model['target'], model['csv']))\n",
    "#  for type in model['types_list']:\n",
    "#    print(\"  %s\" % type)\n",
    "#  for value in model['skip']:\n",
    "#    print(\"  %d\" % int(value))\n",
    "#raise StopExecution\n",
    "\n",
    "# Perform the training for each model\n",
    "import json\n",
    "!export CUBLAS_WORKSPACE_CONFIG=:4096:2\n",
    "for model in model_list:\n",
    "  resultsdict = {}\n",
    "  for skip in model['skip']:\n",
    "    for type in model['types_list']:\n",
    "      # Write config file under ./Configs on-the-fly\n",
    "      types_args = type.split('-')\n",
    "      unit_type = types_args[0]\n",
    "      hidden_size = int(types_args[1])\n",
    "      loss_functions = {\"ESR\": 0.75, \"DC\": 0.25}\n",
    "      pre_filt = \"A-Weighting\"\n",
    "      device = \"aidadsp-auto\"\n",
    "      file_name = \"aidadsp-auto\"\n",
    "      samplerate = \"48000\"\n",
    "      author = \"Aida DSP\"\n",
    "      model_name = \"RNN-\" + device\n",
    "      config = \"Configs/RNN-%s.json\" % device\n",
    "      # Create config file on the fly\n",
    "      config_data = {}\n",
    "      config_data['hidden_size'] = hidden_size\n",
    "      config_data['unit_type'] = unit_type\n",
    "      config_data['loss_functions'] = loss_functions\n",
    "      config_data['pre_filt'] = pre_filt\n",
    "      config_data['skip'] = skip\n",
    "      config_data['device'] = device\n",
    "      config_data['file_name'] = file_name\n",
    "      config_data['samplerate'] = samplerate\n",
    "      config_data['author'] = author\n",
    "      json_string = json.dumps(config_data)\n",
    "      json_file = open(config, \"w\")\n",
    "      json_file.write(json_string)\n",
    "      json_file.close()\n",
    "      input_file = model['input']\n",
    "      target_file = model['target']\n",
    "      # Create dataset on-the-fly\n",
    "      if model['csv'] == \"yes\":\n",
    "        !python3 prep_wav.py -f \"$input_file\" \"$target_file\" -l $model_name -csv\n",
    "      else:\n",
    "        !python3 prep_wav.py -f \"$input_file\" \"$target_file\" -l $model_name\n",
    "      # Perform training\n",
    "      from time import time, gmtime, strftime\n",
    "      start = time()\n",
    "      !python3 dist_model_recnet.py -l $model_name -slen 24000 --seed 39 -lm False\n",
    "      end = time()\n",
    "      delta = end - start\n",
    "      print(strftime(\"%H:%M:%S\", gmtime(delta)))\n",
    "      # Convert json model file to RTNural format\n",
    "      !python3 modelToKeras.py -l $model_name\n",
    "      # Copy meaningful data to an output dir for later analysis\n",
    "      now = !date +\"%Y-%m-%d-%H:%M:%S\"\n",
    "      result_path = \"Results/Jupyter/%s_%s\" % (now[0], model_name)\n",
    "      !mkdir -p $result_path\n",
    "      #!tar czf $result_path/Data.tar.gz /content/Automated-GuitarAmpModelling/Data\n",
    "      !tar czf $result_path/TensorboardData.tar.gz -C TensorboardData .\n",
    "      !rm -rf TensorboardData\n",
    "      #!tar czf $result_path/Results.tar.gz -C Results/*$model_name .\n",
    "      !cp Results/*$model_name/model*.json Results/*$model_name/training_stats.json $result_path/\n",
    "      meaningful_name = model['name']\n",
    "      !cp $result_path/model_keras.json $result_path/$meaningful_name.json \n",
    "      !cp $config $result_path/\n",
    "      # Update dict with training results\n",
    "      result_dir = \"Results/\" + device + \"-\" + model_name\n",
    "      stats = result_dir + \"/training_stats.json\"\n",
    "      [esr, entry] = parse_stats(stats)\n",
    "      resultsdict[esr] = entry\n",
    "      !rm -rf Results/*$model_name\n",
    "  # Write sorted results on a file\n",
    "  result_file = \"Results/Jupyter/%s_%s.txt\" % (now[0], model_name)\n",
    "  write_results_dict(resultsdict, result_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Automated-GuitarAmpModelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
